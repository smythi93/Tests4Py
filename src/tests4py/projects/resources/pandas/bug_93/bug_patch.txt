diff --git a/pandas/core/arrays/datetimelike.py b/pandas/core/arrays/datetimelike.py
index 0fadf3a05..a10e0f63b 100644
--- a/pandas/core/arrays/datetimelike.py
+++ b/pandas/core/arrays/datetimelike.py
@@ -1,1724 +1,961 @@
-from datetime import datetime, timedelta
+"""
+Base and utility classes for tseries type pandas objects.
+"""
 import operator
-from typing import Any, Sequence, Type, Union, cast
-import warnings
+from typing import List, Optional, Set
 
 import numpy as np
 
-from pandas._libs import NaT, NaTType, Timestamp, algos, iNaT, lib
-from pandas._libs.tslibs.c_timestamp import integer_op_not_supported
-from pandas._libs.tslibs.period import DIFFERENT_FREQ, IncompatibleFrequency, Period
-from pandas._libs.tslibs.timedeltas import Timedelta, delta_to_nanoseconds
-from pandas._libs.tslibs.timestamps import RoundTo, round_nsint64
-from pandas._typing import DatetimeLikeScalar
-from pandas.compat import set_function_name
+from pandas._libs import NaT, iNaT, join as libjoin, lib
+from pandas._libs.algos import unique_deltas
+from pandas._libs.tslibs import timezones
 from pandas.compat.numpy import function as nv
-from pandas.errors import AbstractMethodError, NullFrequencyError, PerformanceWarning
-from pandas.util._decorators import Appender, Substitution
-from pandas.util._validators import validate_fillna_kwargs
+from pandas.errors import AbstractMethodError
+from pandas.util._decorators import Appender, cache_readonly
 
 from pandas.core.dtypes.common import (
+    ensure_int64,
+    is_bool_dtype,
     is_categorical_dtype,
-    is_datetime64_any_dtype,
-    is_datetime64_dtype,
-    is_datetime64tz_dtype,
-    is_datetime_or_timedelta_dtype,
     is_dtype_equal,
-    is_float_dtype,
-    is_integer_dtype,
+    is_float,
+    is_integer,
     is_list_like,
-    is_object_dtype,
     is_period_dtype,
-    is_string_dtype,
-    is_timedelta64_dtype,
-    is_unsigned_integer_dtype,
-    pandas_dtype,
+    is_scalar,
+    needs_i8_conversion,
+)
+from pandas.core.dtypes.concat import concat_compat
+from pandas.core.dtypes.generic import ABCIndex, ABCIndexClass, ABCSeries
+from pandas.core.dtypes.missing import isna
+
+from pandas.core import algorithms
+from pandas.core.accessor import PandasDelegate
+from pandas.core.arrays import (
+    DatetimeArray,
+    ExtensionArray,
+    ExtensionOpsMixin,
+    TimedeltaArray,
+)
+from pandas.core.arrays.datetimelike import DatetimeLikeArrayMixin
+import pandas.core.indexes.base as ibase
+from pandas.core.indexes.base import Index, _index_shared_docs
+from pandas.core.indexes.numeric import Int64Index
+from pandas.core.ops import get_op_result_name
+from pandas.core.tools.timedeltas import to_timedelta
+
+from pandas.tseries.frequencies import DateOffset, to_offset
+
+from .extension import (
+    ExtensionIndex,
+    inherit_names,
+    make_wrapped_arith_op,
+    make_wrapped_comparison_op,
 )
-from pandas.core.dtypes.generic import ABCIndexClass, ABCPeriodArray, ABCSeries
-from pandas.core.dtypes.inference import is_array_like
-from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna
-
-from pandas.core import missing, nanops, ops
-from pandas.core.algorithms import checked_add_with_arr, take, unique1d, value_counts
-import pandas.core.common as com
-from pandas.core.indexers import check_bool_array_indexer
-from pandas.core.ops.common import unpack_zerodim_and_defer
-from pandas.core.ops.invalid import invalid_comparison, make_invalid_op
-
-from pandas.tseries import frequencies
-from pandas.tseries.offsets import DateOffset, Tick
 
-from .base import ExtensionArray, ExtensionOpsMixin
+_index_doc_kwargs = dict(ibase._index_doc_kwargs)
 
 
-def _datetimelike_array_cmp(cls, op):
+def _join_i8_wrapper(joinf, with_indexers: bool = True):
     """
-    Wrap comparison operations to convert Timestamp/Timedelta/Period-like to
-    boxed scalars/arrays.
+    Create the join wrapper methods.
     """
-    opname = f"__{op.__name__}__"
-    nat_result = opname == "__ne__"
 
-    @unpack_zerodim_and_defer(opname)
-    def wrapper(self, other):
-
-        if isinstance(other, str):
-            try:
-                # GH#18435 strings get a pass from tzawareness compat
-                other = self._scalar_from_string(other)
-            except ValueError:
-                # failed to parse as Timestamp/Timedelta/Period
-                return invalid_comparison(self, other, op)
+    @staticmethod  # type: ignore
+    def wrapper(left, right):
+        if isinstance(left, (np.ndarray, ABCIndex, ABCSeries, DatetimeLikeArrayMixin)):
+            left = left.view("i8")
+        if isinstance(right, (np.ndarray, ABCIndex, ABCSeries, DatetimeLikeArrayMixin)):
+            right = right.view("i8")
 
-        if isinstance(other, self._recognized_scalars) or other is NaT:
-            other = self._scalar_type(other)
-            self._check_compatible_with(other)
+        results = joinf(left, right)
+        if with_indexers:
+            # dtype should be timedelta64[ns] for TimedeltaIndex
+            #  and datetime64[ns] for DatetimeIndex
+            dtype = left.dtype.base
 
-            other_i8 = self._unbox_scalar(other)
+            join_index, left_indexer, right_indexer = results
+            join_index = join_index.view(dtype)
+            return join_index, left_indexer, right_indexer
+        return results
 
-            result = op(self.view("i8"), other_i8)
-            if isna(other):
-                result.fill(nat_result)
-
-        elif not is_list_like(other):
-            return invalid_comparison(self, other, op)
-
-        elif len(other) != len(self):
-            raise ValueError("Lengths must match")
-
-        else:
-            if isinstance(other, list):
-                # TODO: could use pd.Index to do inference?
-                other = np.array(other)
-
-            if not isinstance(other, (np.ndarray, type(self))):
-                return invalid_comparison(self, other, op)
-
-            if is_object_dtype(other):
-                # We have to use comp_method_OBJECT_ARRAY instead of numpy
-                #  comparison otherwise it would fail to raise when
-                #  comparing tz-aware and tz-naive
-                with np.errstate(all="ignore"):
-                    result = ops.comp_method_OBJECT_ARRAY(
-                        op, self.astype(object), other
-                    )
-                o_mask = isna(other)
-
-            elif not type(self)._is_recognized_dtype(other.dtype):
-                return invalid_comparison(self, other, op)
-
-            else:
-                # For PeriodDType this casting is unnecessary
-                other = type(self)._from_sequence(other)
-                self._check_compatible_with(other)
+    return wrapper
 
-                result = op(self.view("i8"), other.view("i8"))
-                o_mask = other._isnan
-
-            if o_mask.any():
-                result[o_mask] = nat_result
-
-        if self._hasnans:
-            result[self._isnan] = nat_result
-
-        return result
-
-    return set_function_name(wrapper, opname, cls)
 
+@inherit_names(
+    ["inferred_freq", "_isnan", "_resolution", "resolution"],
+    DatetimeLikeArrayMixin,
+    cache=True,
+)
+@inherit_names(
+    ["__iter__", "mean", "freq", "freqstr", "_ndarray_values", "asi8", "_box_values"],
+    DatetimeLikeArrayMixin,
+)
+class DatetimeIndexOpsMixin(ExtensionIndex, ExtensionOpsMixin):
+    """
+    Common ops mixin to support a unified interface datetimelike Index.
+    """
 
-class AttributesMixin:
-    _data: np.ndarray
+    _data: ExtensionArray
+    freq: Optional[DateOffset]
+    freqstr: Optional[str]
+    _resolution: int
+    _bool_ops: List[str] = []
+    _field_ops: List[str] = []
 
-    @classmethod
-    def _simple_new(cls, values, **kwargs):
-        raise AbstractMethodError(cls)
+    hasnans = cache_readonly(DatetimeLikeArrayMixin._hasnans.fget)  # type: ignore
+    _hasnans = hasnans  # for index / array -agnostic code
 
     @property
-    def _scalar_type(self) -> Type[DatetimeLikeScalar]:
-        """The scalar associated with this datelike
+    def is_all_dates(self) -> bool:
+        return True
 
-        * PeriodArray : Period
-        * DatetimeArray : Timestamp
-        * TimedeltaArray : Timedelta
+    @classmethod
+    def _create_comparison_method(cls, op):
         """
-        raise AbstractMethodError(self)
-
-    def _scalar_from_string(
-        self, value: str
-    ) -> Union[Period, Timestamp, Timedelta, NaTType]:
+        Create a comparison method that dispatches to ``cls.values``.
         """
-        Construct a scalar type from a string.
+        return make_wrapped_comparison_op(f"__{op.__name__}__")
 
-        Parameters
-        ----------
-        value : str
+    # ------------------------------------------------------------------------
+    # Abstract data attributes
 
-        Returns
-        -------
-        Period, Timestamp, or Timedelta, or NaT
-            Whatever the type of ``self._scalar_type`` is.
+    @property
+    def values(self):
+        # Note: PeriodArray overrides this to return an ndarray of objects.
+        return self._data._data
 
-        Notes
-        -----
-        This should call ``self._check_compatible_with`` before
-        unboxing the result.
+    def __array_wrap__(self, result, context=None):
         """
-        raise AbstractMethodError(self)
-
-    def _unbox_scalar(self, value: Union[Period, Timestamp, Timedelta, NaTType]) -> int:
+        Gets called after a ufunc.
         """
-        Unbox the integer value of a scalar `value`.
+        result = lib.item_from_zerodim(result)
+        if is_bool_dtype(result) or lib.is_scalar(result):
+            return result
 
-        Parameters
-        ----------
-        value : Union[Period, Timestamp, Timedelta]
+        attrs = self._get_attributes_dict()
+        if not is_period_dtype(self) and attrs["freq"]:
+            # no need to infer if freq is None
+            attrs["freq"] = "infer"
+        return Index(result, **attrs)
 
-        Returns
-        -------
-        int
+    # ------------------------------------------------------------------------
 
-        Examples
-        --------
-        >>> self._unbox_scalar(Timedelta('10s'))  # DOCTEST: +SKIP
-        10000000000
+    def equals(self, other) -> bool:
         """
-        raise AbstractMethodError(self)
-
-    def _check_compatible_with(
-        self, other: Union[Period, Timestamp, Timedelta, NaTType], setitem: bool = False
-    ) -> None:
+        Determines if two Index objects contain the same elements.
         """
-        Verify that `self` and `other` are compatible.
+        if self.is_(other):
+            return True
 
-        * DatetimeArray verifies that the timezones (if any) match
-        * PeriodArray verifies that the freq matches
-        * Timedelta has no verification
-
-        In each case, NaT is considered compatible.
+        if not isinstance(other, ABCIndexClass):
+            return False
+        elif not isinstance(other, type(self)):
+            try:
+                other = type(self)(other)
+            except (ValueError, TypeError, OverflowError):
+                # e.g.
+                #  ValueError -> cannot parse str entry, or OutOfBoundsDatetime
+                #  TypeError  -> trying to convert IntervalIndex to DatetimeIndex
+                #  OverflowError -> Index([very_large_timedeltas])
+                return False
+
+        if not is_dtype_equal(self.dtype, other.dtype):
+            # have different timezone
+            return False
+
+        return np.array_equal(self.asi8, other.asi8)
+
+    @Appender(_index_shared_docs["contains"] % _index_doc_kwargs)
+    def __contains__(self, key):
+        try:
+            res = self.get_loc(key)
+            return (
+                is_scalar(res)
+                or isinstance(res, slice)
+                or (is_list_like(res) and len(res))
+            )
+        except (KeyError, TypeError, ValueError):
+            return False
 
-        Parameters
-        ----------
-        other
-        setitem : bool, default False
-            For __setitem__ we may have stricter compatiblity resrictions than
-            for comparisons.
-
-        Raises
-        ------
-        Exception
-        """
-        raise AbstractMethodError(self)
+    # Try to run function on index first, and then on elements of index
+    # Especially important for group-by functionality
+    def map(self, mapper, na_action=None):
+        try:
+            result = mapper(self)
 
+            # Try to use this result if we can
+            if isinstance(result, np.ndarray):
+                result = Index(result)
 
-class DatelikeOps:
-    """
-    Common ops for DatetimeIndex/PeriodIndex, but not TimedeltaIndex.
-    """
+            if not isinstance(result, Index):
+                raise TypeError("The map function must return an Index object")
+            return result
+        except Exception:
+            return self.astype(object).map(mapper)
 
-    @Substitution(
-        URL="https://docs.python.org/3/library/datetime.html"
-        "#strftime-and-strptime-behavior"
-    )
-    def strftime(self, date_format):
+    def sort_values(self, return_indexer=False, ascending=True):
         """
-        Convert to Index using specified date_format.
-
-        Return an Index of formatted strings specified by date_format, which
-        supports the same string format as the python standard library. Details
-        of the string format can be found in `python string format
-        doc <%(URL)s>`__.
-
-        Parameters
-        ----------
-        date_format : str
-            Date format string (e.g. "%%Y-%%m-%%d").
-
-        Returns
-        -------
-        ndarray
-            NumPy ndarray of formatted strings.
-
-        See Also
-        --------
-        to_datetime : Convert the given argument to datetime.
-        DatetimeIndex.normalize : Return DatetimeIndex with times to midnight.
-        DatetimeIndex.round : Round the DatetimeIndex to the specified freq.
-        DatetimeIndex.floor : Floor the DatetimeIndex to the specified freq.
-
-        Examples
-        --------
-        >>> rng = pd.date_range(pd.Timestamp("2018-03-10 09:00"),
-        ...                     periods=3, freq='s')
-        >>> rng.strftime('%%B %%d, %%Y, %%r')
-        Index(['March 10, 2018, 09:00:00 AM', 'March 10, 2018, 09:00:01 AM',
-               'March 10, 2018, 09:00:02 AM'],
-              dtype='object')
+        Return sorted copy of Index.
         """
-        result = self._format_native_types(date_format=date_format, na_rep=np.nan)
-        return result.astype(object)
-
-
-class TimelikeOps:
-    """
-    Common ops for TimedeltaIndex/DatetimeIndex, but not PeriodIndex.
-    """
-
-    _round_doc = """
-        Perform {op} operation on the data to the specified `freq`.
-
-        Parameters
-        ----------
-        freq : str or Offset
-            The frequency level to {op} the index to. Must be a fixed
-            frequency like 'S' (second) not 'ME' (month end). See
-            :ref:`frequency aliases <timeseries.offset_aliases>` for
-            a list of possible `freq` values.
-        ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'
-            Only relevant for DatetimeIndex:
-
-            - 'infer' will attempt to infer fall dst-transition hours based on
-              order
-            - bool-ndarray where True signifies a DST time, False designates
-              a non-DST time (note that this flag is only applicable for
-              ambiguous times)
-            - 'NaT' will return NaT where there are ambiguous times
-            - 'raise' will raise an AmbiguousTimeError if there are ambiguous
-              times.
+        if return_indexer:
+            _as = self.argsort()
+            if not ascending:
+                _as = _as[::-1]
+            sorted_index = self.take(_as)
+            return sorted_index, _as
+        else:
+            # NB: using asi8 instead of _ndarray_values matters in numpy 1.18
+            #  because the treatment of NaT has been changed to put NaT last
+            #  instead of first.
+            sorted_values = np.sort(self.asi8)
+            attribs = self._get_attributes_dict()
+            freq = attribs["freq"]
+
+            if freq is not None and not is_period_dtype(self):
+                if freq.n > 0 and not ascending:
+                    freq = freq * -1
+                elif freq.n < 0 and ascending:
+                    freq = freq * -1
+            attribs["freq"] = freq
+
+            if not ascending:
+                sorted_values = sorted_values[::-1]
+
+            return self._simple_new(sorted_values, **attribs)
+
+    @Appender(_index_shared_docs["take"] % _index_doc_kwargs)
+    def take(self, indices, axis=0, allow_fill=True, fill_value=None, **kwargs):
+        nv.validate_take(tuple(), kwargs)
+        indices = ensure_int64(indices)
+
+        maybe_slice = lib.maybe_indices_to_slice(indices, len(self))
+        if isinstance(maybe_slice, slice):
+            return self[maybe_slice]
+
+        return ExtensionIndex.take(
+            self, indices, axis, allow_fill, fill_value, **kwargs
+        )
 
-            .. versionadded:: 0.24.0
+    _can_hold_na = True
 
-        nonexistent : 'shift_forward', 'shift_backward', 'NaT', timedelta, \
-default 'raise'
-            A nonexistent time does not exist in a particular timezone
-            where clocks moved forward due to DST.
+    _na_value = NaT
+    """The expected NA value to use with this index."""
 
-            - 'shift_forward' will shift the nonexistent time forward to the
-              closest existing time
-            - 'shift_backward' will shift the nonexistent time backward to the
-              closest existing time
-            - 'NaT' will return NaT where there are nonexistent times
-            - timedelta objects will shift nonexistent times by the timedelta
-            - 'raise' will raise an NonExistentTimeError if there are
-              nonexistent times.
+    def _convert_tolerance(self, tolerance, target):
+        tolerance = np.asarray(to_timedelta(tolerance).to_numpy())
 
-            .. versionadded:: 0.24.0
+        if target.size != tolerance.size and tolerance.size > 1:
+            raise ValueError("list-like tolerance size must match target index size")
+        return tolerance
 
-        Returns
-        -------
-        DatetimeIndex, TimedeltaIndex, or Series
-            Index of the same type for a DatetimeIndex or TimedeltaIndex,
-            or a Series with the same index for a Series.
+    def tolist(self) -> List:
+        """
+        Return a list of the underlying data.
+        """
+        return list(self.astype(object))
 
-        Raises
-        ------
-        ValueError if the `freq` cannot be converted.
+    def min(self, axis=None, skipna=True, *args, **kwargs):
+        """
+        Return the minimum value of the Index or minimum along
+        an axis.
 
-        Examples
+        See Also
         --------
-        **DatetimeIndex**
-
-        >>> rng = pd.date_range('1/1/2018 11:59:00', periods=3, freq='min')
-        >>> rng
-        DatetimeIndex(['2018-01-01 11:59:00', '2018-01-01 12:00:00',
-                       '2018-01-01 12:01:00'],
-                      dtype='datetime64[ns]', freq='T')
+        numpy.ndarray.min
+        Series.min : Return the minimum value in a Series.
         """
+        nv.validate_min(args, kwargs)
+        nv.validate_minmax_axis(axis)
 
-    _round_example = """>>> rng.round('H')
-        DatetimeIndex(['2018-01-01 12:00:00', '2018-01-01 12:00:00',
-                       '2018-01-01 12:00:00'],
-                      dtype='datetime64[ns]', freq=None)
+        if not len(self):
+            return self._na_value
 
-        **Series**
+        i8 = self.asi8
+        try:
+            # quick check
+            if len(i8) and self.is_monotonic:
+                if i8[0] != iNaT:
+                    return self._box_func(i8[0])
+
+            if self.hasnans:
+                if skipna:
+                    min_stamp = self[~self._isnan].asi8.min()
+                else:
+                    return self._na_value
+            else:
+                min_stamp = i8.min()
+            return self._box_func(min_stamp)
+        except ValueError:
+            return self._na_value
 
-        >>> pd.Series(rng).dt.round("H")
-        0   2018-01-01 12:00:00
-        1   2018-01-01 12:00:00
-        2   2018-01-01 12:00:00
-        dtype: datetime64[ns]
+    def argmin(self, axis=None, skipna=True, *args, **kwargs):
         """
+        Returns the indices of the minimum values along an axis.
 
-    _floor_example = """>>> rng.floor('H')
-        DatetimeIndex(['2018-01-01 11:00:00', '2018-01-01 12:00:00',
-                       '2018-01-01 12:00:00'],
-                      dtype='datetime64[ns]', freq=None)
-
-        **Series**
+        See `numpy.ndarray.argmin` for more information on the
+        `axis` parameter.
 
-        >>> pd.Series(rng).dt.floor("H")
-        0   2018-01-01 11:00:00
-        1   2018-01-01 12:00:00
-        2   2018-01-01 12:00:00
-        dtype: datetime64[ns]
+        See Also
+        --------
+        numpy.ndarray.argmin
         """
+        nv.validate_argmin(args, kwargs)
+        nv.validate_minmax_axis(axis)
 
-    _ceil_example = """>>> rng.ceil('H')
-        DatetimeIndex(['2018-01-01 12:00:00', '2018-01-01 12:00:00',
-                       '2018-01-01 13:00:00'],
-                      dtype='datetime64[ns]', freq=None)
-
-        **Series**
+        i8 = self.asi8
+        if self.hasnans:
+            mask = self._isnan
+            if mask.all() or not skipna:
+                return -1
+            i8 = i8.copy()
+            i8[mask] = np.iinfo("int64").max
+        return i8.argmin()
 
-        >>> pd.Series(rng).dt.ceil("H")
-        0   2018-01-01 12:00:00
-        1   2018-01-01 12:00:00
-        2   2018-01-01 13:00:00
-        dtype: datetime64[ns]
+    def max(self, axis=None, skipna=True, *args, **kwargs):
         """
+        Return the maximum value of the Index or maximum along
+        an axis.
 
-    def _round(self, freq, mode, ambiguous, nonexistent):
-        # round the local times
-        values = _ensure_datetimelike_to_i8(self)
-        result = round_nsint64(values, mode, freq)
-        result = self._maybe_mask_results(result, fill_value=NaT)
-
-        dtype = self.dtype
-        if is_datetime64tz_dtype(self):
-            dtype = None
-        return self._ensure_localized(
-            self._simple_new(result, dtype=dtype), ambiguous, nonexistent
-        )
-
-    @Appender((_round_doc + _round_example).format(op="round"))
-    def round(self, freq, ambiguous="raise", nonexistent="raise"):
-        return self._round(freq, RoundTo.NEAREST_HALF_EVEN, ambiguous, nonexistent)
-
-    @Appender((_round_doc + _floor_example).format(op="floor"))
-    def floor(self, freq, ambiguous="raise", nonexistent="raise"):
-        return self._round(freq, RoundTo.MINUS_INFTY, ambiguous, nonexistent)
-
-    @Appender((_round_doc + _ceil_example).format(op="ceil"))
-    def ceil(self, freq, ambiguous="raise", nonexistent="raise"):
-        return self._round(freq, RoundTo.PLUS_INFTY, ambiguous, nonexistent)
+        See Also
+        --------
+        numpy.ndarray.max
+        Series.max : Return the maximum value in a Series.
+        """
+        nv.validate_max(args, kwargs)
+        nv.validate_minmax_axis(axis)
 
+        if not len(self):
+            return self._na_value
 
-class DatetimeLikeArrayMixin(ExtensionOpsMixin, AttributesMixin, ExtensionArray):
-    """
-    Shared Base/Mixin class for DatetimeArray, TimedeltaArray, PeriodArray
+        i8 = self.asi8
+        try:
+            # quick check
+            if len(i8) and self.is_monotonic:
+                if i8[-1] != iNaT:
+                    return self._box_func(i8[-1])
+
+            if self.hasnans:
+                if skipna:
+                    max_stamp = self[~self._isnan].asi8.max()
+                else:
+                    return self._na_value
+            else:
+                max_stamp = i8.max()
+            return self._box_func(max_stamp)
+        except ValueError:
+            return self._na_value
 
-    Assumes that __new__/__init__ defines:
-        _data
-        _freq
+    def argmax(self, axis=None, skipna=True, *args, **kwargs):
+        """
+        Returns the indices of the maximum values along an axis.
 
-    and that the inheriting class has methods:
-        _generate_range
-    """
+        See `numpy.ndarray.argmax` for more information on the
+        `axis` parameter.
 
-    @property
-    def ndim(self) -> int:
-        return self._data.ndim
+        See Also
+        --------
+        numpy.ndarray.argmax
+        """
+        nv.validate_argmax(args, kwargs)
+        nv.validate_minmax_axis(axis)
 
-    @property
-    def shape(self):
-        return self._data.shape
+        i8 = self.asi8
+        if self.hasnans:
+            mask = self._isnan
+            if mask.all() or not skipna:
+                return -1
+            i8 = i8.copy()
+            i8[mask] = 0
+        return i8.argmax()
 
-    def reshape(self, *args, **kwargs):
-        # Note: we drop any freq
-        data = self._data.reshape(*args, **kwargs)
-        return type(self)(data, dtype=self.dtype)
+    # --------------------------------------------------------------------
+    # Rendering Methods
 
-    def ravel(self, *args, **kwargs):
-        # Note: we drop any freq
-        data = self._data.ravel(*args, **kwargs)
-        return type(self)(data, dtype=self.dtype)
+    def _format_with_header(self, header, na_rep="NaT", **kwargs):
+        return header + list(self._format_native_types(na_rep, **kwargs))
 
     @property
-    def _box_func(self):
-        """
-        box function to get object from internal representation
-        """
+    def _formatter_func(self):
         raise AbstractMethodError(self)
 
-    def _box_values(self, values):
+    def _format_attrs(self):
         """
-        apply box func to passed values
+        Return a list of tuples of the (attr,formatted_value).
         """
-        return lib.map_infer(values, self._box_func)
+        attrs = super()._format_attrs()
+        for attrib in self._attributes:
+            if attrib == "freq":
+                freq = self.freqstr
+                if freq is not None:
+                    freq = repr(freq)
+                attrs.append(("freq", freq))
+        return attrs
 
-    def __iter__(self):
-        return (self._box_func(v) for v in self.asi8)
+    # --------------------------------------------------------------------
 
-    @property
-    def asi8(self) -> np.ndarray:
+    def _convert_scalar_indexer(self, key, kind=None):
         """
-        Integer representation of the values.
+        We don't allow integer or float indexing on datetime-like when using
+        loc.
 
-        Returns
-        -------
-        ndarray
-            An ndarray with int64 dtype.
-        """
-        # do not cache or you'll create a memory leak
-        return self._data.view("i8")
-
-    @property
-    def _ndarray_values(self):
-        return self._data
-
-    # ----------------------------------------------------------------
-    # Rendering Methods
+        Parameters
+        ----------
+        key : label of the slice bound
+        kind : {'ix', 'loc', 'getitem', 'iloc'} or None
+        """
+
+        assert kind in ["ix", "loc", "getitem", "iloc", None]
+
+        # we don't allow integer/float indexing for loc
+        # we don't allow float indexing for ix/getitem
+        if is_scalar(key):
+            is_int = is_integer(key)
+            is_flt = is_float(key)
+            if kind in ["loc"] and (is_int or is_flt):
+                self._invalid_indexer("index", key)
+            elif kind in ["ix", "getitem"] and is_flt:
+                self._invalid_indexer("index", key)
+
+        return super()._convert_scalar_indexer(key, kind=kind)
+
+    __add__ = make_wrapped_arith_op("__add__")
+    __radd__ = make_wrapped_arith_op("__radd__")
+    __sub__ = make_wrapped_arith_op("__sub__")
+    __rsub__ = make_wrapped_arith_op("__rsub__")
+    __pow__ = make_wrapped_arith_op("__pow__")
+    __rpow__ = make_wrapped_arith_op("__rpow__")
+    __mul__ = make_wrapped_arith_op("__mul__")
+    __rmul__ = make_wrapped_arith_op("__rmul__")
+    __floordiv__ = make_wrapped_arith_op("__floordiv__")
+    __rfloordiv__ = make_wrapped_arith_op("__rfloordiv__")
+    __mod__ = make_wrapped_arith_op("__mod__")
+    __rmod__ = make_wrapped_arith_op("__rmod__")
+    __divmod__ = make_wrapped_arith_op("__divmod__")
+    __rdivmod__ = make_wrapped_arith_op("__rdivmod__")
+    __truediv__ = make_wrapped_arith_op("__truediv__")
+    __rtruediv__ = make_wrapped_arith_op("__rtruediv__")
+
+    def isin(self, values, level=None):
+        """
+        Compute boolean array of whether each index value is found in the
+        passed set of values.
 
-    def _format_native_types(self, na_rep="NaT", date_format=None):
-        """
-        Helper method for astype when converting to strings.
+        Parameters
+        ----------
+        values : set or sequence of values
 
         Returns
         -------
-        ndarray[str]
+        is_contained : ndarray (boolean dtype)
         """
-        raise AbstractMethodError(self)
-
-    def _formatter(self, boxed=False):
-        # TODO: Remove Datetime & DatetimeTZ formatters.
-        return "'{}'".format
-
-    # ----------------------------------------------------------------
-    # Array-Like / EA-Interface Methods
-
-    @property
-    def nbytes(self):
-        return self._data.nbytes
-
-    def __array__(self, dtype=None):
-        # used for Timedelta/DatetimeArray, overwritten by PeriodArray
-        if is_object_dtype(dtype):
-            return np.array(list(self), dtype=object)
-        return self._data
-
-    @property
-    def size(self) -> int:
-        """The number of elements in this array."""
-        return np.prod(self.shape)
+        if level is not None:
+            self._validate_index_level(level)
 
-    def __len__(self) -> int:
-        return len(self._data)
+        if not isinstance(values, type(self)):
+            try:
+                values = type(self)(values)
+            except ValueError:
+                return self.astype(object).isin(values)
 
-    def __getitem__(self, key):
-        """
-        This getitem defers to the underlying array, which by-definition can
-        only handle list-likes, slices, and integer scalars
-        """
+        return algorithms.isin(self.asi8, values.asi8)
 
-        is_int = lib.is_integer(key)
-        if lib.is_scalar(key) and not is_int:
-            raise IndexError(
-                "only integers, slices (`:`), ellipsis (`...`), "
-                "numpy.newaxis (`None`) and integer or boolean "
-                "arrays are valid indices"
-            )
+    @Appender(_index_shared_docs["repeat"] % _index_doc_kwargs)
+    def repeat(self, repeats, axis=None):
+        nv.validate_repeat(tuple(), dict(axis=axis))
+        result = type(self._data)(self.asi8.repeat(repeats), dtype=self.dtype)
+        return self._shallow_copy(result)
 
-        getitem = self._data.__getitem__
-        if is_int:
-            val = getitem(key)
-            if lib.is_scalar(val):
-                # i.e. self.ndim == 1
-                return self._box_func(val)
-            return type(self)(val, dtype=self.dtype)
-
-        if com.is_bool_indexer(key):
-            key = check_bool_array_indexer(self, key)
-            if key.all():
-                key = slice(0, None, None)
-            else:
-                key = lib.maybe_booleans_to_slice(key.view(np.uint8))
+    @Appender(_index_shared_docs["where"] % _index_doc_kwargs)
+    def where(self, cond, other=None):
+        values = self.view("i8")
 
-        is_period = is_period_dtype(self)
-        if is_period:
-            freq = self.freq
-        else:
-            freq = None
-            if isinstance(key, slice):
-                if self.freq is not None and key.step is not None:
-                    freq = key.step * self.freq
-                else:
-                    freq = self.freq
-            elif key is Ellipsis:
-                # GH#21282 indexing with Ellipsis is similar to a full slice,
-                #  should preserve `freq` attribute
-                freq = self.freq
-
-        result = getitem(key)
-        if result.ndim > 1:
-            # To support MPL which performs slicing with 2 dim
-            # even though it only has 1 dim by definition
-            if is_period:
-                return self._simple_new(result, dtype=self.dtype, freq=freq)
-            return result
+        if is_scalar(other) and isna(other):
+            other = NaT.value
 
-        return self._simple_new(result, dtype=self.dtype, freq=freq)
-
-    def __setitem__(
-        self,
-        key: Union[int, Sequence[int], Sequence[bool], slice],
-        value: Union[NaTType, Any, Sequence[Any]],
-    ) -> None:
-        # I'm fudging the types a bit here. "Any" above really depends
-        # on type(self). For PeriodArray, it's Period (or stuff coercible
-        # to a period in from_sequence). For DatetimeArray, it's Timestamp...
-        # I don't know if mypy can do that, possibly with Generics.
-        # https://mypy.readthedocs.io/en/latest/generics.html
-        if lib.is_scalar(value) and not isna(value):
-            value = com.maybe_box_datetimelike(value)
-
-        if is_list_like(value):
-            is_slice = isinstance(key, slice)
-
-            if lib.is_scalar(key):
-                raise ValueError("setting an array element with a sequence.")
-
-            if not is_slice:
-                key = cast(Sequence, key)
-                if len(key) != len(value) and not com.is_bool_indexer(key):
-                    msg = (
-                        f"shape mismatch: value array of length '{len(key)}' "
-                        "does not match indexing result of length "
-                        f"'{len(value)}'."
-                    )
-                    raise ValueError(msg)
-                elif not len(key):
-                    return
-
-            value = type(self)._from_sequence(value, dtype=self.dtype)
-            self._check_compatible_with(value, setitem=True)
-            value = value.asi8
-        elif isinstance(value, self._scalar_type):
-            self._check_compatible_with(value, setitem=True)
-            value = self._unbox_scalar(value)
-        elif is_valid_nat_for_dtype(value, self.dtype):
-            value = iNaT
         else:
-            msg = (
-                f"'value' should be a '{self._scalar_type.__name__}', 'NaT', "
-                f"or array of those. Got '{type(value).__name__}' instead."
-            )
-            raise TypeError(msg)
-        self._data[key] = value
-        self._maybe_clear_freq()
-
-    def _maybe_clear_freq(self):
-        # inplace operations like __setitem__ may invalidate the freq of
-        # DatetimeArray and TimedeltaArray
-        pass
+            # Do type inference if necessary up front
+            # e.g. we passed PeriodIndex.values and got an ndarray of Periods
+            other = Index(other)
 
-    def astype(self, dtype, copy=True):
-        # Some notes on cases we don't have to handle here in the base class:
-        #   1. PeriodArray.astype handles period -> period
-        #   2. DatetimeArray.astype handles conversion between tz.
-        #   3. DatetimeArray.astype handles datetime -> period
-        from pandas import Categorical
-
-        dtype = pandas_dtype(dtype)
-
-        if is_object_dtype(dtype):
-            return self._box_values(self.asi8)
-        elif is_string_dtype(dtype) and not is_categorical_dtype(dtype):
-            return self._format_native_types()
-        elif is_integer_dtype(dtype):
-            # we deliberately ignore int32 vs. int64 here.
-            # See https://github.com/pandas-dev/pandas/issues/24381 for more.
-            values = self.asi8
-
-            if is_unsigned_integer_dtype(dtype):
-                # Again, we ignore int32 vs. int64
-                values = values.view("uint64")
-
-            if copy:
-                values = values.copy()
-            return values
-        elif (
-            is_datetime_or_timedelta_dtype(dtype)
-            and not is_dtype_equal(self.dtype, dtype)
-        ) or is_float_dtype(dtype):
-            # disallow conversion between datetime/timedelta,
-            # and conversions for any datetimelike to float
-            msg = f"Cannot cast {type(self).__name__} to dtype {dtype}"
-            raise TypeError(msg)
-        elif is_categorical_dtype(dtype):
-            return Categorical(self, dtype=dtype)
-        else:
-            return np.asarray(self, dtype=dtype)
+            if is_categorical_dtype(other):
+                # e.g. we have a Categorical holding self.dtype
+                if needs_i8_conversion(other.categories):
+                    other = other._internal_get_values()
 
-    def view(self, dtype=None):
-        if dtype is None or dtype is self.dtype:
-            return type(self)(self._data, dtype=self.dtype)
-        return self._data.view(dtype=dtype)
+            if not is_dtype_equal(self.dtype, other.dtype):
+                raise TypeError(f"Where requires matching dtype, not {other.dtype}")
 
-    # ------------------------------------------------------------------
-    # ExtensionArray Interface
+            other = other.view("i8")
 
-    def unique(self):
-        result = unique1d(self.asi8)
-        return type(self)(result, dtype=self.dtype)
+        result = np.where(cond, values, other).astype("i8")
+        return self._shallow_copy(result)
 
-    def _validate_fill_value(self, fill_value):
+    def _summary(self, name=None):
         """
-        If a fill_value is passed to `take` convert it to an i8 representation,
-        raising ValueError if this is not possible.
+        Return a summarized representation.
 
         Parameters
         ----------
-        fill_value : object
+        name : str
+            Name to use in the summary representation.
 
         Returns
         -------
-        fill_value : np.int64
-
-        Raises
-        ------
-        ValueError
+        str
+            Summarized representation of the index.
         """
-        if isna(fill_value):
-            fill_value = iNaT
-        elif isinstance(fill_value, self._recognized_scalars):
-            self._check_compatible_with(fill_value)
-            fill_value = self._scalar_type(fill_value)
-            fill_value = self._unbox_scalar(fill_value)
+        formatter = self._formatter_func
+        if len(self) > 0:
+            index_summary = f", {formatter(self[0])} to {formatter(self[-1])}"
         else:
-            raise ValueError(
-                f"'fill_value' should be a {self._scalar_type}. Got '{fill_value}'."
-            )
-        return fill_value
-
-    def take(self, indices, allow_fill=False, fill_value=None):
-        if allow_fill:
-            fill_value = self._validate_fill_value(fill_value)
+            index_summary = ""
 
-        new_values = take(
-            self.asi8, indices, allow_fill=allow_fill, fill_value=fill_value
-        )
+        if name is None:
+            name = type(self).__name__
+        result = f"{name}: {len(self)} entries{index_summary}"
+        if self.freq:
+            result += f"\nFreq: {self.freqstr}"
 
-        return type(self)(new_values, dtype=self.dtype)
+        # display as values, not quoted
+        result = result.replace("'", "")
+        return result
 
-    @classmethod
-    def _concat_same_type(cls, to_concat):
-        dtypes = {x.dtype for x in to_concat}
-        assert len(dtypes) == 1
-        dtype = list(dtypes)[0]
+    def _concat_same_dtype(self, to_concat, name):
+        """
+        Concatenate to_concat which has the same class.
+        """
+        attribs = self._get_attributes_dict()
+        attribs["name"] = name
+        # do not pass tz to set because tzlocal cannot be hashed
+        if len({str(x.dtype) for x in to_concat}) != 1:
+            raise ValueError("to_concat must have the same tz")
 
-        values = np.concatenate([x.asi8 for x in to_concat])
-        return cls(values, dtype=dtype)
+        new_data = type(self._values)._concat_same_type(to_concat).asi8
 
-    def copy(self):
-        values = self.asi8.copy()
-        return type(self)._simple_new(values, dtype=self.dtype, freq=self.freq)
+        # GH 3232: If the concat result is evenly spaced, we can retain the
+        # original frequency
+        is_diff_evenly_spaced = len(unique_deltas(new_data)) == 1
+        if not is_period_dtype(self) and not is_diff_evenly_spaced:
+            # reset freq
+            attribs["freq"] = None
 
-    def _values_for_factorize(self):
-        return self.asi8, iNaT
+        return self._simple_new(new_data, **attribs)
 
-    @classmethod
-    def _from_factorized(cls, values, original):
-        return cls(values, dtype=original.dtype)
+    @Appender(_index_shared_docs["astype"])
+    def astype(self, dtype, copy=True):
+        if is_dtype_equal(self.dtype, dtype) and copy is False:
+            # Ensure that self.astype(self.dtype) is self
+            return self
 
-    def _values_for_argsort(self):
-        return self._data
+        new_values = self._data.astype(dtype, copy=copy)
 
-    # ------------------------------------------------------------------
-    # Additional array methods
-    #  These are not part of the EA API, but we implement them because
-    #  pandas assumes they're there.
+        # pass copy=False because any copying will be done in the
+        #  _data.astype call above
+        return Index(new_values, dtype=new_values.dtype, name=self.name, copy=False)
 
-    def searchsorted(self, value, side="left", sorter=None):
+    def shift(self, periods=1, freq=None):
         """
-        Find indices where elements should be inserted to maintain order.
+        Shift index by desired number of time frequency increments.
 
-        Find the indices into a sorted array `self` such that, if the
-        corresponding elements in `value` were inserted before the indices,
-        the order of `self` would be preserved.
+        This method is for shifting the values of datetime-like indexes
+        by a specified time increment a given number of times.
 
         Parameters
         ----------
-        value : array_like
-            Values to insert into `self`.
-        side : {'left', 'right'}, optional
-            If 'left', the index of the first suitable location found is given.
-            If 'right', return the last such index.  If there is no suitable
-            index, return either 0 or N (where N is the length of `self`).
-        sorter : 1-D array_like, optional
-            Optional array of integer indices that sort `self` into ascending
-            order. They are typically the result of ``np.argsort``.
+        periods : int, default 1
+            Number of periods (or increments) to shift by,
+            can be positive or negative.
 
-        Returns
-        -------
-        indices : array of ints
-            Array of insertion points with the same shape as `value`.
-        """
-        if isinstance(value, str):
-            value = self._scalar_from_string(value)
+            .. versionchanged:: 0.24.0
 
-        if not (isinstance(value, (self._scalar_type, type(self))) or isna(value)):
-            raise ValueError(f"Unexpected type for 'value': {type(value)}")
-
-        self._check_compatible_with(value)
-        if isinstance(value, type(self)):
-            value = value.asi8
-        else:
-            value = self._unbox_scalar(value)
-
-        return self.asi8.searchsorted(value, side=side, sorter=sorter)
+        freq : pandas.DateOffset, pandas.Timedelta or string, optional
+            Frequency increment to shift by.
+            If None, the index is shifted by its own `freq` attribute.
+            Offset aliases are valid strings, e.g., 'D', 'W', 'M' etc.
 
-    def repeat(self, repeats, *args, **kwargs):
-        """
-        Repeat elements of an array.
+        Returns
+        -------
+        pandas.DatetimeIndex
+            Shifted index.
 
         See Also
         --------
-        numpy.ndarray.repeat
-        """
-        nv.validate_repeat(args, kwargs)
-        values = self._data.repeat(repeats)
-        return type(self)(values.view("i8"), dtype=self.dtype)
-
-    def value_counts(self, dropna=False):
+        Index.shift : Shift values of Index.
+        PeriodIndex.shift : Shift values of PeriodIndex.
         """
-        Return a Series containing counts of unique values.
+        result = self._data._time_shift(periods, freq=freq)
+        return type(self)(result, name=self.name)
 
-        Parameters
-        ----------
-        dropna : bool, default True
-            Don't include counts of NaT values.
+    # --------------------------------------------------------------------
+    # List-like Methods
 
-        Returns
-        -------
-        Series
-        """
-        from pandas import Series, Index
+    def delete(self, loc):
+        new_i8s = np.delete(self.asi8, loc)
 
-        if dropna:
-            values = self[~self.isna()]._data
+        freq = None
+        if is_period_dtype(self):
+            freq = self.freq
+        elif is_integer(loc):
+            if loc in (0, -len(self), -1, len(self) - 1):
+                freq = self.freq
         else:
-            values = self._data
-
-        cls = type(self)
-
-        result = value_counts(values, sort=False, dropna=dropna)
-        index = Index(
-            cls(result.index.view("i8"), dtype=self.dtype), name=result.index.name
-        )
-        return Series(result.values, index=index, name=result.name)
+            if is_list_like(loc):
+                loc = lib.maybe_indices_to_slice(ensure_int64(np.array(loc)), len(self))
+            if isinstance(loc, slice) and loc.step in (1, None):
+                if loc.start in (0, None) or loc.stop in (len(self), None):
+                    freq = self.freq
 
-    def map(self, mapper):
-        # TODO(GH-23179): Add ExtensionArray.map
-        # Need to figure out if we want ExtensionArray.map first.
-        # If so, then we can refactor IndexOpsMixin._map_values to
-        # a standalone function and call from here..
-        # Else, just rewrite _map_infer_values to do the right thing.
-        from pandas import Index
+        return self._shallow_copy(new_i8s, freq=freq)
 
-        return Index(self).map(mapper).array
 
-    # ------------------------------------------------------------------
-    # Null Handling
+class DatetimeTimedeltaMixin(DatetimeIndexOpsMixin, Int64Index):
+    """
+    Mixin class for methods shared by DatetimeIndex and TimedeltaIndex,
+    but not PeriodIndex
+    """
 
-    def isna(self):
-        return self._isnan
+    # Compat for frequency inference, see GH#23789
+    _is_monotonic_increasing = Index.is_monotonic_increasing
+    _is_monotonic_decreasing = Index.is_monotonic_decreasing
+    _is_unique = Index.is_unique
 
-    @property  # NB: override with cache_readonly in immutable subclasses
-    def _isnan(self):
-        """
-        return if each value is nan
+    def _set_freq(self, freq):
         """
-        return self.asi8 == iNaT
+        Set the _freq attribute on our underlying DatetimeArray.
 
-    @property  # NB: override with cache_readonly in immutable subclasses
-    def _hasnans(self):
-        """
-        return if I have any nans; enables various perf speedups
-        """
-        return bool(self._isnan.any())
-
-    def _maybe_mask_results(self, result, fill_value=iNaT, convert=None):
-        """
         Parameters
         ----------
-        result : a ndarray
-        fill_value : object, default iNaT
-        convert : str, dtype or None
-
-        Returns
-        -------
-        result : ndarray with values replace by the fill_value
-
-        mask the result if needed, convert to the provided dtype if its not
-        None
-
-        This is an internal routine.
-        """
-
-        if self._hasnans:
-            if convert:
-                result = result.astype(convert)
-            if fill_value is None:
-                fill_value = np.nan
-            result[self._isnan] = fill_value
-        return result
-
-    def fillna(self, value=None, method=None, limit=None):
-        # TODO(GH-20300): remove this
-        # Just overriding to ensure that we avoid an astype(object).
-        # Either 20300 or a `_values_for_fillna` would avoid this duplication.
-        if isinstance(value, ABCSeries):
-            value = value.array
-
-        value, method = validate_fillna_kwargs(value, method)
-
-        mask = self.isna()
-
-        if is_array_like(value):
-            if len(value) != len(self):
-                raise ValueError(
-                    f"Length of 'value' does not match. Got ({len(value)}) "
-                    f" expected {len(self)}"
-                )
-            value = value[mask]
-
-        if mask.any():
-            if method is not None:
-                if method == "pad":
-                    func = missing.pad_1d
-                else:
-                    func = missing.backfill_1d
-
-                values = self._data
-                if not is_period_dtype(self):
-                    # For PeriodArray self._data is i8, which gets copied
-                    #  by `func`.  Otherwise we need to make a copy manually
-                    # to avoid modifying `self` in-place.
-                    values = values.copy()
-
-                new_values = func(values, limit=limit, mask=mask)
-                if is_datetime64tz_dtype(self):
-                    # we need to pass int64 values to the constructor to avoid
-                    #  re-localizing incorrectly
-                    new_values = new_values.view("i8")
-                new_values = type(self)(new_values, dtype=self.dtype)
-            else:
-                # fill with value
-                new_values = self.copy()
-                new_values[mask] = value
+        freq : DateOffset, None, or "infer"
+        """
+        # GH#29843
+        if freq is None:
+            # Always valid
+            pass
+        elif len(self) == 0 and isinstance(freq, DateOffset):
+            # Always valid.  In the TimedeltaIndex case, we assume this
+            #  is a Tick offset.
+            pass
         else:
-            new_values = self.copy()
-        return new_values
+            # As an internal method, we can ensure this assertion always holds
+            assert freq == "infer"
+            freq = to_offset(self.inferred_freq)
 
-    # ------------------------------------------------------------------
-    # Frequency Properties/Methods
+        self._data._freq = freq
 
-    @property
-    def freq(self):
-        """
-        Return the frequency object if it is set, otherwise None.
-        """
-        return self._freq
+    def _shallow_copy(self, values=None, **kwargs):
+        if values is None:
+            values = self._data
+        if isinstance(values, type(self)):
+            values = values._data
 
-    @freq.setter
-    def freq(self, value):
-        if value is not None:
-            value = frequencies.to_offset(value)
-            self._validate_frequency(self, value)
+        attributes = self._get_attributes_dict()
 
-        self._freq = value
+        if "freq" not in kwargs and self.freq is not None:
+            if isinstance(values, (DatetimeArray, TimedeltaArray)):
+                if values.freq is None:
+                    del attributes["freq"]
 
-    @property
-    def freqstr(self):
-        """
-        Return the frequency object as a string if its set, otherwise None
-        """
-        if self.freq is None:
-            return None
-        return self.freq.freqstr
+        attributes.update(kwargs)
+        return self._simple_new(values, **attributes)
 
-    @property  # NB: override with cache_readonly in immutable subclasses
-    def inferred_freq(self):
-        """
-        Tryies to return a string representing a frequency guess,
-        generated by infer_freq.  Returns None if it can't autodetect the
-        frequency.
-        """
-        if self.ndim != 1:
-            return None
-        try:
-            return frequencies.infer_freq(self)
-        except ValueError:
-            return None
+    # --------------------------------------------------------------------
+    # Set Operation Methods
 
-    @property  # NB: override with cache_readonly in immutable subclasses
-    def _resolution(self):
-        return frequencies.Resolution.get_reso_from_freq(self.freqstr)
+    @Appender(Index.difference.__doc__)
+    def difference(self, other, sort=None):
+        new_idx = super().difference(other, sort=sort)
+        new_idx._set_freq(None)
+        return new_idx
 
-    @property  # NB: override with cache_readonly in immutable subclasses
-    def resolution(self):
-        """
-        Returns day, hour, minute, second, millisecond or microsecond
+    def intersection(self, other, sort=False):
         """
-        return frequencies.Resolution.get_str(self._resolution)
+        Specialized intersection for DatetimeIndex/TimedeltaIndex.
 
-    @classmethod
-    def _validate_frequency(cls, index, freq, **kwargs):
-        """
-        Validate that a frequency is compatible with the values of a given
-        Datetime Array/Index or Timedelta Array/Index
+        May be much faster than Index.intersection
 
         Parameters
         ----------
-        index : DatetimeIndex or TimedeltaIndex
-            The index on which to determine if the given frequency is valid
-        freq : DateOffset
-            The frequency to validate
-        """
-        if is_period_dtype(cls):
-            # Frequency validation is not meaningful for Period Array/Index
-            return None
-
-        inferred = index.inferred_freq
-        if index.size == 0 or inferred == freq.freqstr:
-            return None
+        other : Same type as self or array-like
+        sort : False or None, default False
+            Sort the resulting index if possible.
 
-        try:
-            on_freq = cls._generate_range(
-                start=index[0], end=None, periods=len(index), freq=freq, **kwargs
-            )
-            if not np.array_equal(index.asi8, on_freq.asi8):
-                raise ValueError
-        except ValueError as e:
-            if "non-fixed" in str(e):
-                # non-fixed frequencies are not meaningful for timedelta64;
-                #  we retain that error message
-                raise e
-            # GH#11587 the main way this is reached is if the `np.array_equal`
-            #  check above is False.  This can also be reached if index[0]
-            #  is `NaT`, in which case the call to `cls._generate_range` will
-            #  raise a ValueError, which we re-raise with a more targeted
-            #  message.
-            raise ValueError(
-                f"Inferred frequency {inferred} from passed values "
-                f"does not conform to passed frequency {freq.freqstr}"
-            )
-
-    # monotonicity/uniqueness properties are called via frequencies.infer_freq,
-    #  see GH#23789
-
-    @property
-    def _is_monotonic_increasing(self):
-        return algos.is_monotonic(self.asi8, timelike=True)[0]
+            .. versionadded:: 0.24.0
 
-    @property
-    def _is_monotonic_decreasing(self):
-        return algos.is_monotonic(self.asi8, timelike=True)[1]
+            .. versionchanged:: 0.24.1
 
-    @property
-    def _is_unique(self):
-        return len(unique1d(self.asi8)) == len(self)
-
-    # ------------------------------------------------------------------
-    # Arithmetic Methods
-    _create_comparison_method = classmethod(_datetimelike_array_cmp)
-
-    # pow is invalid for all three subclasses; TimedeltaArray will override
-    #  the multiplication and division ops
-    __pow__ = make_invalid_op("__pow__")
-    __rpow__ = make_invalid_op("__rpow__")
-    __mul__ = make_invalid_op("__mul__")
-    __rmul__ = make_invalid_op("__rmul__")
-    __truediv__ = make_invalid_op("__truediv__")
-    __rtruediv__ = make_invalid_op("__rtruediv__")
-    __floordiv__ = make_invalid_op("__floordiv__")
-    __rfloordiv__ = make_invalid_op("__rfloordiv__")
-    __mod__ = make_invalid_op("__mod__")
-    __rmod__ = make_invalid_op("__rmod__")
-    __divmod__ = make_invalid_op("__divmod__")
-    __rdivmod__ = make_invalid_op("__rdivmod__")
-
-    def _add_datetimelike_scalar(self, other):
-        # Overridden by TimedeltaArray
-        raise TypeError(f"cannot add {type(self).__name__} and {type(other).__name__}")
-
-    _add_datetime_arraylike = _add_datetimelike_scalar
-
-    def _sub_datetimelike_scalar(self, other):
-        # Overridden by DatetimeArray
-        assert other is not NaT
-        raise TypeError(f"cannot subtract a datelike from a {type(self).__name__}")
-
-    _sub_datetime_arraylike = _sub_datetimelike_scalar
-
-    def _sub_period(self, other):
-        # Overridden by PeriodArray
-        raise TypeError(f"cannot subtract Period from a {type(self).__name__}")
-
-    def _add_offset(self, offset):
-        raise AbstractMethodError(self)
+               Changed the default to ``False`` to match the behaviour
+               from before 0.24.0.
 
-    def _add_delta(self, other):
-        """
-        Add a timedelta-like, Tick or TimedeltaIndex-like object
-        to self, yielding an int64 numpy array
+            .. versionchanged:: 0.25.0
 
-        Parameters
-        ----------
-        delta : {timedelta, np.timedelta64, Tick,
-                 TimedeltaIndex, ndarray[timedelta64]}
+               The `sort` keyword is added
 
         Returns
         -------
-        result : ndarray[int64]
-
-        Notes
-        -----
-        The result's name is set outside of _add_delta by the calling
-        method (__add__ or __sub__), if necessary (i.e. for Indexes).
+        y : Index or same type as self
         """
-        if isinstance(other, (Tick, timedelta, np.timedelta64)):
-            new_values = self._add_timedeltalike_scalar(other)
-        elif is_timedelta64_dtype(other):
-            # ndarray[timedelta64] or TimedeltaArray/index
-            new_values = self._add_delta_tdi(other)
+        self._validate_sort_keyword(sort)
+        self._assert_can_do_setop(other)
 
-        return new_values
+        if self.equals(other):
+            return self._get_reconciled_name_object(other)
 
-    def _add_timedeltalike_scalar(self, other):
-        """
-        Add a delta of a timedeltalike
-        return the i8 result view
-        """
-        if isna(other):
-            # i.e np.timedelta64("NaT"), not recognized by delta_to_nanoseconds
-            new_values = np.empty(self.shape, dtype="i8")
-            new_values[:] = iNaT
-            return new_values
-
-        inc = delta_to_nanoseconds(other)
-        new_values = checked_add_with_arr(self.asi8, inc, arr_mask=self._isnan).view(
-            "i8"
-        )
-        new_values = self._maybe_mask_results(new_values)
-        return new_values.view("i8")
-
-    def _add_delta_tdi(self, other):
-        """
-        Add a delta of a TimedeltaIndex
-        return the i8 result view
-        """
-        if len(self) != len(other):
-            raise ValueError("cannot add indices of unequal length")
+        if len(self) == 0:
+            return self.copy()
+        if len(other) == 0:
+            return other.copy()
+
+        if not isinstance(other, type(self)):
+            result = Index.intersection(self, other, sort=sort)
+            if isinstance(result, type(self)):
+                if result.freq is None:
+                    result._set_freq("infer")
+            return result
 
-        if isinstance(other, np.ndarray):
-            # ndarray[timedelta64]; wrap in TimedeltaIndex for op
-            from pandas.core.arrays import TimedeltaArray
+        elif (
+            other.freq is None
+            or self.freq is None
+            or other.freq != self.freq
+            or not other.freq.is_anchored()
+            or (not self.is_monotonic or not other.is_monotonic)
+        ):
+            result = Index.intersection(self, other, sort=sort)
 
-            other = TimedeltaArray._from_sequence(other)
+            # Invalidate the freq of `result`, which may not be correct at
+            # this point, depending on the values.
 
-        self_i8 = self.asi8
-        other_i8 = other.asi8
-        new_values = checked_add_with_arr(
-            self_i8, other_i8, arr_mask=self._isnan, b_mask=other._isnan
-        )
-        if self._hasnans or other._hasnans:
-            mask = (self._isnan) | (other._isnan)
-            new_values[mask] = iNaT
-        return new_values.view("i8")
-
-    def _add_nat(self):
-        """
-        Add pd.NaT to self
-        """
-        if is_period_dtype(self):
-            raise TypeError(
-                f"Cannot add {type(self).__name__} and {type(NaT).__name__}"
+            result._set_freq(None)
+            result = self._shallow_copy(
+                result._data, name=result.name, dtype=result.dtype, freq=None
             )
+            if result.freq is None:
+                result._set_freq("infer")
+            return result
 
-        # GH#19124 pd.NaT is treated like a timedelta for both timedelta
-        # and datetime dtypes
-        result = np.zeros(self.shape, dtype=np.int64)
-        result.fill(iNaT)
-        return type(self)(result, dtype=self.dtype, freq=None)
-
-    def _sub_nat(self):
-        """
-        Subtract pd.NaT from self
-        """
-        # GH#19124 Timedelta - datetime is not in general well-defined.
-        # We make an exception for pd.NaT, which in this case quacks
-        # like a timedelta.
-        # For datetime64 dtypes by convention we treat NaT as a datetime, so
-        # this subtraction returns a timedelta64 dtype.
-        # For period dtype, timedelta64 is a close-enough return dtype.
-        result = np.zeros(self.shape, dtype=np.int64)
-        result.fill(iNaT)
-        return result.view("timedelta64[ns]")
-
-    def _sub_period_array(self, other):
-        """
-        Subtract a Period Array/Index from self.  This is only valid if self
-        is itself a Period Array/Index, raises otherwise.  Both objects must
-        have the same frequency.
+        # to make our life easier, "sort" the two ranges
+        if self[0] <= other[0]:
+            left, right = self, other
+        else:
+            left, right = other, self
 
-        Parameters
-        ----------
-        other : PeriodIndex or PeriodArray
+        # after sorting, the intersection always starts with the right index
+        # and ends with the index of which the last elements is smallest
+        end = min(left[-1], right[-1])
+        start = right[0]
 
-        Returns
-        -------
-        result : np.ndarray[object]
-            Array of DateOffset objects; nulls represented by NaT.
-        """
-        if not is_period_dtype(self):
-            raise TypeError(
-                f"cannot subtract {other.dtype}-dtype from {type(self).__name__}"
-            )
+        if end < start:
+            return type(self)(data=[])
+        else:
+            lslice = slice(*left.slice_locs(start, end))
+            left_chunk = left.values[lslice]
+            return self._shallow_copy(left_chunk)
 
-        if self.freq != other.freq:
-            msg = DIFFERENT_FREQ.format(
-                cls=type(self).__name__, own_freq=self.freqstr, other_freq=other.freqstr
-            )
-            raise IncompatibleFrequency(msg)
+    def _can_fast_union(self, other) -> bool:
+        if not isinstance(other, type(self)):
+            return False
 
-        new_values = checked_add_with_arr(
-            self.asi8, -other.asi8, arr_mask=self._isnan, b_mask=other._isnan
-        )
+        freq = self.freq
 
-        new_values = np.array([self.freq.base * x for x in new_values])
-        if self._hasnans or other._hasnans:
-            mask = (self._isnan) | (other._isnan)
-            new_values[mask] = NaT
-        return new_values
+        if freq is None or freq != other.freq:
+            return False
 
-    def _addsub_object_array(self, other: np.ndarray, op):
-        """
-        Add or subtract array-like of DateOffset objects
+        if not self.is_monotonic or not other.is_monotonic:
+            return False
 
-        Parameters
-        ----------
-        other : np.ndarray[object]
-        op : {operator.add, operator.sub}
+        if len(self) == 0 or len(other) == 0:
+            return True
 
-        Returns
-        -------
-        result : same class as self
-        """
-        assert op in [operator.add, operator.sub]
-        if len(other) == 1:
-            return op(self, other[0])
-
-        warnings.warn(
-            "Adding/subtracting array of DateOffsets to "
-            f"{type(self).__name__} not vectorized",
-            PerformanceWarning,
-        )
+        # to make our life easier, "sort" the two ranges
+        if self[0] <= other[0]:
+            left, right = self, other
+        else:
+            left, right = other, self
 
-        # For EA self.astype('O') returns a numpy array, not an Index
-        left = self.astype("O")
+        right_start = right[0]
+        left_end = left[-1]
 
-        res_values = op(left, np.array(other))
-        kwargs = {}
-        if not is_period_dtype(self):
-            kwargs["freq"] = "infer"
+        # Only need to "adjoin", not overlap
         try:
-            res = type(self)._from_sequence(res_values, **kwargs)
+            return (right_start == left_end + freq) or right_start in left
         except ValueError:
-            # e.g. we've passed a Timestamp to TimedeltaArray
-            res = res_values
-        return res
-
-    def _time_shift(self, periods, freq=None):
-        """
-        Shift each value by `periods`.
-
-        Note this is different from ExtensionArray.shift, which
-        shifts the *position* of each element, padding the end with
-        missing values.
-
-        Parameters
-        ----------
-        periods : int
-            Number of periods to shift by.
-        freq : pandas.DateOffset, pandas.Timedelta, or str
-            Frequency increment to shift by.
-        """
-        if freq is not None and freq != self.freq:
-            if isinstance(freq, str):
-                freq = frequencies.to_offset(freq)
-            offset = periods * freq
-            result = self + offset
-            return result
-
-        if periods == 0:
-            # immutable so OK
-            return self.copy()
-
-        if self.freq is None:
-            raise NullFrequencyError("Cannot shift with no freq")
-
-        start = self[0] + periods * self.freq
-        end = self[-1] + periods * self.freq
-
-        # Note: in the DatetimeTZ case, _generate_range will infer the
-        #  appropriate timezone from `start` and `end`, so tz does not need
-        #  to be passed explicitly.
-        return self._generate_range(start=start, end=end, periods=None, freq=self.freq)
-
-    @unpack_zerodim_and_defer("__add__")
-    def __add__(self, other):
-
-        # scalar others
-        if other is NaT:
-            result = self._add_nat()
-        elif isinstance(other, (Tick, timedelta, np.timedelta64)):
-            result = self._add_delta(other)
-        elif isinstance(other, DateOffset):
-            # specifically _not_ a Tick
-            result = self._add_offset(other)
-        elif isinstance(other, (datetime, np.datetime64)):
-            result = self._add_datetimelike_scalar(other)
-        elif lib.is_integer(other):
-            # This check must come after the check for np.timedelta64
-            # as is_integer returns True for these
-            if not is_period_dtype(self):
-                raise integer_op_not_supported(self)
-            result = self._time_shift(other)
-
-        # array-like others
-        elif is_timedelta64_dtype(other):
-            # TimedeltaIndex, ndarray[timedelta64]
-            result = self._add_delta(other)
-        elif is_object_dtype(other):
-            # e.g. Array/Index of DateOffset objects
-            result = self._addsub_object_array(other, operator.add)
-        elif is_datetime64_dtype(other) or is_datetime64tz_dtype(other):
-            # DatetimeIndex, ndarray[datetime64]
-            return self._add_datetime_arraylike(other)
-        elif is_integer_dtype(other):
-            if not is_period_dtype(self):
-                raise integer_op_not_supported(self)
-            result = self._addsub_int_array(other, operator.add)
+            # if we are comparing a freq that does not propagate timezones
+            # this will raise
+            return False
+
+    def _fast_union(self, other, sort=None):
+        if len(other) == 0:
+            return self.view(type(self))
+
+        if len(self) == 0:
+            return other.view(type(self))
+
+        # to make our life easier, "sort" the two ranges
+        if self[0] <= other[0]:
+            left, right = self, other
+        elif sort is False:
+            # TDIs are not in the "correct" order and we don't want
+            #  to sort but want to remove overlaps
+            left, right = self, other
+            left_start = left[0]
+            loc = right.searchsorted(left_start, side="left")
+            right_chunk = right.values[:loc]
+            dates = concat_compat((left.values, right_chunk))
+            return self._shallow_copy(dates)
         else:
-            # Includes Categorical, other ExtensionArrays
-            # For PeriodDtype, if self is a TimedeltaArray and other is a
-            #  PeriodArray with  a timedelta-like (i.e. Tick) freq, this
-            #  operation is valid.  Defer to the PeriodArray implementation.
-            #  In remaining cases, this will end up raising TypeError.
-            return NotImplemented
+            left, right = other, self
 
-        if is_timedelta64_dtype(result) and isinstance(result, np.ndarray):
-            from pandas.core.arrays import TimedeltaArray
-
-            return TimedeltaArray(result)
-        return result
+        left_end = left[-1]
+        right_end = right[-1]
 
-    def __radd__(self, other):
-        # alias for __add__
-        return self.__add__(other)
-
-    @unpack_zerodim_and_defer("__sub__")
-    def __sub__(self, other):
-
-        # scalar others
-        if other is NaT:
-            result = self._sub_nat()
-        elif isinstance(other, (Tick, timedelta, np.timedelta64)):
-            result = self._add_delta(-other)
-        elif isinstance(other, DateOffset):
-            # specifically _not_ a Tick
-            result = self._add_offset(-other)
-        elif isinstance(other, (datetime, np.datetime64)):
-            result = self._sub_datetimelike_scalar(other)
-        elif lib.is_integer(other):
-            # This check must come after the check for np.timedelta64
-            # as is_integer returns True for these
-            if not is_period_dtype(self):
-                raise integer_op_not_supported(self)
-            result = self._time_shift(-other)
-
-        elif isinstance(other, Period):
-            result = self._sub_period(other)
-
-        # array-like others
-        elif is_timedelta64_dtype(other):
-            # TimedeltaIndex, ndarray[timedelta64]
-            result = self._add_delta(-other)
-        elif is_object_dtype(other):
-            # e.g. Array/Index of DateOffset objects
-            result = self._addsub_object_array(other, operator.sub)
-        elif is_datetime64_dtype(other) or is_datetime64tz_dtype(other):
-            # DatetimeIndex, ndarray[datetime64]
-            result = self._sub_datetime_arraylike(other)
-        elif is_period_dtype(other):
-            # PeriodIndex
-            result = self._sub_period_array(other)
-        elif is_integer_dtype(other):
-            if not is_period_dtype(self):
-                raise integer_op_not_supported(self)
-            result = self._addsub_int_array(other, operator.sub)
+        # concatenate
+        if left_end < right_end:
+            loc = right.searchsorted(left_end, side="right")
+            right_chunk = right.values[loc:]
+            dates = concat_compat((left.values, right_chunk))
+            return self._shallow_copy(dates)
         else:
-            # Includes ExtensionArrays, float_dtype
-            return NotImplemented
+            return left
 
-        if is_timedelta64_dtype(result) and isinstance(result, np.ndarray):
-            from pandas.core.arrays import TimedeltaArray
+    def _union(self, other, sort):
+        if not len(other) or self.equals(other) or not len(self):
+            return super()._union(other, sort=sort)
 
-            return TimedeltaArray(result)
-        return result
+        # We are called by `union`, which is responsible for this validation
+        assert isinstance(other, type(self))
 
-    def __rsub__(self, other):
-        if is_datetime64_any_dtype(other) and is_timedelta64_dtype(self.dtype):
-            # ndarray[datetime64] cannot be subtracted from self, so
-            # we need to wrap in DatetimeArray/Index and flip the operation
-            if lib.is_scalar(other):
-                # i.e. np.datetime64 object
-                return Timestamp(other) - self
-            if not isinstance(other, DatetimeLikeArrayMixin):
-                # Avoid down-casting DatetimeIndex
-                from pandas.core.arrays import DatetimeArray
-
-                other = DatetimeArray(other)
-            return other - self
-        elif (
-            is_datetime64_any_dtype(self.dtype)
-            and hasattr(other, "dtype")
-            and not is_datetime64_any_dtype(other.dtype)
-        ):
-            # GH#19959 datetime - datetime is well-defined as timedelta,
-            # but any other type - datetime is not well-defined.
-            raise TypeError(
-                f"cannot subtract {type(self).__name__} from {type(other).__name__}"
-            )
-        elif is_period_dtype(self.dtype) and is_timedelta64_dtype(other):
-            # TODO: Can we simplify/generalize these cases at all?
-            raise TypeError(f"cannot subtract {type(self).__name__} from {other.dtype}")
-        elif is_timedelta64_dtype(self.dtype):
-            if lib.is_integer(other) or is_integer_dtype(other):
-                # need to subtract before negating, since that flips freq
-                # -self flips self.freq, messing up results
-                return -(self - other)
-
-            return (-self) + other
-
-        return -(self - other)
-
-    def __iadd__(self, other):  # type: ignore
-        result = self + other
-        self[:] = result[:]
-
-        if not is_period_dtype(self):
-            # restore freq, which is invalidated by setitem
-            self._freq = result._freq
-        return self
-
-    def __isub__(self, other):  # type: ignore
-        result = self - other
-        self[:] = result[:]
-
-        if not is_period_dtype(self):
-            # restore freq, which is invalidated by setitem
-            self._freq = result._freq
-        return self
-
-    # --------------------------------------------------------------
-    # Comparison Methods
-
-    def _ensure_localized(
-        self, arg, ambiguous="raise", nonexistent="raise", from_utc=False
-    ):
-        """
-        Ensure that we are re-localized.
+        this, other = self._maybe_utc_convert(other)
 
-        This is for compat as we can then call this on all datetimelike
-        arrays generally (ignored for Period/Timedelta)
-
-        Parameters
-        ----------
-        arg : Union[DatetimeLikeArray, DatetimeIndexOpsMixin, ndarray]
-        ambiguous : str, bool, or bool-ndarray, default 'raise'
-        nonexistent : str, default 'raise'
-        from_utc : bool, default False
-            If True, localize the i8 ndarray to UTC first before converting to
-            the appropriate tz. If False, localize directly to the tz.
-
-        Returns
-        -------
-        localized array
-        """
-
-        # reconvert to local tz
-        tz = getattr(self, "tz", None)
-        if tz is not None:
-            if not isinstance(arg, type(self)):
-                arg = self._simple_new(arg)
-            if from_utc:
-                arg = arg.tz_localize("UTC").tz_convert(self.tz)
-            else:
-                arg = arg.tz_localize(
-                    self.tz, ambiguous=ambiguous, nonexistent=nonexistent
-                )
-        return arg
-
-    # --------------------------------------------------------------
-    # Reductions
-
-    def _reduce(self, name, axis=0, skipna=True, **kwargs):
-        op = getattr(self, name, None)
-        if op:
-            return op(skipna=skipna, **kwargs)
+        if this._can_fast_union(other):
+            return this._fast_union(other, sort=sort)
         else:
-            return super()._reduce(name, skipna, **kwargs)
-
-    def min(self, axis=None, skipna=True, *args, **kwargs):
-        """
-        Return the minimum value of the Array or minimum along
-        an axis.
-
-        See Also
-        --------
-        numpy.ndarray.min
-        Index.min : Return the minimum value in an Index.
-        Series.min : Return the minimum value in a Series.
-        """
-        nv.validate_min(args, kwargs)
-        nv.validate_minmax_axis(axis)
+            result = Index._union(this, other, sort=sort)
+            if isinstance(result, type(self)):
+                assert result._data.dtype == this.dtype
+                if result.freq is None:
+                    result._set_freq("infer")
+            return result
 
-        result = nanops.nanmin(self.asi8, skipna=skipna, mask=self.isna())
-        if isna(result):
-            # Period._from_ordinal does not handle np.nan gracefully
-            return NaT
-        return self._box_func(result)
+    # --------------------------------------------------------------------
+    # Join Methods
+    _join_precedence = 10
 
-    def max(self, axis=None, skipna=True, *args, **kwargs):
-        """
-        Return the maximum value of the Array or maximum along
-        an axis.
+    _inner_indexer = _join_i8_wrapper(libjoin.inner_join_indexer)
+    _outer_indexer = _join_i8_wrapper(libjoin.outer_join_indexer)
+    _left_indexer = _join_i8_wrapper(libjoin.left_join_indexer)
+    _left_indexer_unique = _join_i8_wrapper(
+        libjoin.left_join_indexer_unique, with_indexers=False
+    )
 
-        See Also
-        --------
-        numpy.ndarray.max
-        Index.max : Return the maximum value in an Index.
-        Series.max : Return the maximum value in a Series.
+    def join(
+        self, other, how: str = "left", level=None, return_indexers=False, sort=False
+    ):
         """
-        # TODO: skipna is broken with max.
-        # See https://github.com/pandas-dev/pandas/issues/24265
-        nv.validate_max(args, kwargs)
-        nv.validate_minmax_axis(axis)
-
-        mask = self.isna()
-        if skipna:
-            values = self[~mask].asi8
-        elif mask.any():
-            return NaT
-        else:
-            values = self.asi8
-
-        if not len(values):
-            # short-circuit for empty max / min
-            return NaT
-
-        result = nanops.nanmax(values, skipna=skipna)
-        # Don't have to worry about NA `result`, since no NA went in.
-        return self._box_func(result)
-
-    def mean(self, skipna=True):
+        See Index.join
         """
-        Return the mean value of the Array.
-
-        .. versionadded:: 0.25.0
-
-        Parameters
-        ----------
-        skipna : bool, default True
-            Whether to ignore any NaT elements.
+        if self._is_convertible_to_index_for_join(other):
+            try:
+                other = type(self)(other)
+            except (TypeError, ValueError):
+                pass
+
+        this, other = self._maybe_utc_convert(other)
+        return Index.join(
+            this,
+            other,
+            how=how,
+            level=level,
+            return_indexers=return_indexers,
+            sort=sort,
+        )
 
-        Returns
-        -------
-        scalar
-            Timestamp or Timedelta.
+    def _maybe_utc_convert(self, other):
+        this = self
+        if not hasattr(self, "tz"):
+            return this, other
 
-        See Also
-        --------
-        numpy.ndarray.mean : Returns the average of array elements along a given axis.
-        Series.mean : Return the mean value in a Series.
+        if isinstance(other, type(self)):
+            if self.tz is not None:
+                if other.tz is None:
+                    raise TypeError("Cannot join tz-naive with tz-aware DatetimeIndex")
+            elif other.tz is not None:
+                raise TypeError("Cannot join tz-naive with tz-aware DatetimeIndex")
 
-        Notes
-        -----
-        mean is only defined for Datetime and Timedelta dtypes, not for Period.
-        """
-        if is_period_dtype(self):
-            # See discussion in GH#24757
-            raise TypeError(
-                f"mean is not implemented for {type(self).__name__} since the "
-                "meaning is ambiguous.  An alternative is "
-                "obj.to_timestamp(how='start').mean()"
-            )
+            if not timezones.tz_compare(self.tz, other.tz):
+                this = self.tz_convert("UTC")
+                other = other.tz_convert("UTC")
+        return this, other
 
-        mask = self.isna()
-        if skipna:
-            values = self[~mask]
-        elif mask.any():
-            return NaT
+    @classmethod
+    def _is_convertible_to_index_for_join(cls, other: Index) -> bool:
+        """
+        return a boolean whether I can attempt conversion to a
+        DatetimeIndex/TimedeltaIndex
+        """
+        if isinstance(other, cls):
+            return False
+        elif len(other) > 0 and other.inferred_type not in (
+            "floating",
+            "mixed-integer",
+            "integer",
+            "integer-na",
+            "mixed-integer-float",
+            "mixed",
+        ):
+            return True
+        return False
+
+    def _wrap_joined_index(self, joined, other):
+        name = get_op_result_name(self, other)
+        if (
+            isinstance(other, type(self))
+            and self.freq == other.freq
+            and self._can_fast_union(other)
+        ):
+            joined = self._shallow_copy(joined)
+            joined.name = name
+            return joined
         else:
-            values = self
-
-        if not len(values):
-            # short-circuit for empty max / min
-            return NaT
-
-        result = nanops.nanmean(values.view("i8"), skipna=skipna)
-        # Don't have to worry about NA `result`, since no NA went in.
-        return self._box_func(result)
-
-
-DatetimeLikeArrayMixin._add_comparison_ops()
+            kwargs = {}
+            if hasattr(self, "tz"):
+                kwargs["tz"] = getattr(other, "tz", None)
+            return self._simple_new(joined, name, **kwargs)
 
-# -------------------------------------------------------------------
-# Shared Constructor Helpers
 
-
-def validate_periods(periods):
+class DatetimelikeDelegateMixin(PandasDelegate):
     """
-    If a `periods` argument is passed to the Datetime/Timedelta Array/Index
-    constructor, cast it to an integer.
-
-    Parameters
-    ----------
-    periods : None, float, int
-
-    Returns
-    -------
-    periods : None or int
-
-    Raises
-    ------
-    TypeError
-        if periods is None, float, or int
+    Delegation mechanism, specific for Datetime, Timedelta, and Period types.
+
+    Functionality is delegated from the Index class to an Array class. A
+    few things can be customized
+
+    * _delegated_methods, delegated_properties : List
+        The list of property / method names being delagated.
+    * raw_methods : Set
+        The set of methods whose results should should *not* be
+        boxed in an index, after being returned from the array
+    * raw_properties : Set
+        The set of properties whose results should should *not* be
+        boxed in an index, after being returned from the array
     """
-    if periods is not None:
-        if lib.is_float(periods):
-            periods = int(periods)
-        elif not lib.is_integer(periods):
-            raise TypeError(f"periods must be a number, got {periods}")
-    return periods
-
 
-def validate_endpoints(closed):
-    """
-    Check that the `closed` argument is among [None, "left", "right"]
+    # raw_methods : dispatch methods that shouldn't be boxed in an Index
+    _raw_methods: Set[str] = set()
+    # raw_properties : dispatch properties that shouldn't be boxed in an Index
+    _raw_properties: Set[str] = set()
+    _data: ExtensionArray
 
-    Parameters
-    ----------
-    closed : {None, "left", "right"}
-
-    Returns
-    -------
-    left_closed : bool
-    right_closed : bool
-
-    Raises
-    ------
-    ValueError : if argument is not among valid values
-    """
-    left_closed = False
-    right_closed = False
-
-    if closed is None:
-        left_closed = True
-        right_closed = True
-    elif closed == "left":
-        left_closed = True
-    elif closed == "right":
-        right_closed = True
-    else:
-        raise ValueError("Closed has to be either 'left', 'right' or None")
-
-    return left_closed, right_closed
-
-
-def validate_inferred_freq(freq, inferred_freq, freq_infer):
-    """
-    If the user passes a freq and another freq is inferred from passed data,
-    require that they match.
-
-    Parameters
-    ----------
-    freq : DateOffset or None
-    inferred_freq : DateOffset or None
-    freq_infer : bool
-
-    Returns
-    -------
-    freq : DateOffset or None
-    freq_infer : bool
-
-    Notes
-    -----
-    We assume at this point that `maybe_infer_freq` has been called, so
-    `freq` is either a DateOffset object or None.
-    """
-    if inferred_freq is not None:
-        if freq is not None and freq != inferred_freq:
-            raise ValueError(
-                f"Inferred frequency {inferred_freq} from passed "
-                "values does not conform to passed frequency "
-                f"{freq.freqstr}"
-            )
-        elif freq is None:
-            freq = inferred_freq
-        freq_infer = False
-
-    return freq, freq_infer
-
-
-def maybe_infer_freq(freq):
-    """
-    Comparing a DateOffset to the string "infer" raises, so we need to
-    be careful about comparisons.  Make a dummy variable `freq_infer` to
-    signify the case where the given freq is "infer" and set freq to None
-    to avoid comparison trouble later on.
-
-    Parameters
-    ----------
-    freq : {DateOffset, None, str}
-
-    Returns
-    -------
-    freq : {DateOffset, None}
-    freq_infer : bool
-    """
-    freq_infer = False
-    if not isinstance(freq, DateOffset):
-        # if a passed freq is None, don't infer automatically
-        if freq != "infer":
-            freq = frequencies.to_offset(freq)
-        else:
-            freq_infer = True
-            freq = None
-    return freq, freq_infer
+    def _delegate_property_get(self, name, *args, **kwargs):
+        result = getattr(self._data, name)
+        if name not in self._raw_properties:
+            result = Index(result, name=self.name)
+        return result
 
+    def _delegate_property_set(self, name, value, *args, **kwargs):
+        setattr(self._data, name, value)
 
-def _ensure_datetimelike_to_i8(other, to_utc=False):
-    """
-    Helper for coercing an input scalar or array to i8.
-
-    Parameters
-    ----------
-    other : 1d array
-    to_utc : bool, default False
-        If True, convert the values to UTC before extracting the i8 values
-        If False, extract the i8 values directly.
-
-    Returns
-    -------
-    i8 1d array
-    """
-    from pandas import Index
-
-    if lib.is_scalar(other) and isna(other):
-        return iNaT
-    elif isinstance(other, (ABCPeriodArray, ABCIndexClass, DatetimeLikeArrayMixin)):
-        # convert tz if needed
-        if getattr(other, "tz", None) is not None:
-            if to_utc:
-                other = other.tz_convert("UTC")
-            else:
-                other = other.tz_localize(None)
-    else:
-        try:
-            return np.array(other, copy=False).view("i8")
-        except TypeError:
-            # period array cannot be coerced to int
-            other = Index(other)
-    return other.asi8
+    def _delegate_method(self, name, *args, **kwargs):
+        result = operator.methodcaller(name, *args, **kwargs)(self._data)
+        if name not in self._raw_methods:
+            result = Index(result, name=self.name)
+        return result
