diff --git a/keras/engine/training.py b/keras/engine/training.py
index 6cd7d35f..b87874f9 100644
--- a/keras/engine/training.py
+++ b/keras/engine/training.py
@@ -1900,7 +1900,7 @@ class Model(Container):
     @interfaces.legacy_generator_methods_support
     def fit_generator(self,
                       generator,
-                      steps_per_epoch,
+                      steps_per_epoch=None,
                       epochs=1,
                       verbose=1,
                       callbacks=None,
@@ -1941,7 +1941,9 @@ class Model(Container):
                 to yield from `generator` before declaring one epoch
                 finished and starting the next epoch. It should typically
                 be equal to the number of samples of your dataset
-                divided by the batch size. Not used if using `Sequence`.
+                divided by the batch size.
+                Optional for `Sequence`: if unspecified, will use
+                the `len(generator)` as a number of steps.
             epochs: Integer, total number of iterations on the data.
             verbose: Verbosity mode, 0, 1, or 2.
             callbacks: List of callbacks to be called during training.
@@ -1952,6 +1954,8 @@ class Model(Container):
             validation_steps: Only relevant if `validation_data`
                 is a generator. Total number of steps (batches of samples)
                 to yield from `generator` before stopping.
+                Optional for `Sequence`: if unspecified, will use
+                the `len(validation_data)` as a number of steps.
             class_weight: Dictionary mapping class indices to a weight
                 for the class.
             max_queue_size: Integer. Maximum size for the generator queue.
@@ -2005,15 +2009,33 @@ class Model(Container):
         if do_validation:
             self._make_test_function()
 
+        is_sequence = isinstance(generator, Sequence)
+        if not is_sequence and use_multiprocessing and workers > 1:
+            warnings.warn(
+                UserWarning('Using a generator with `use_multiprocessing=True`'
+                            ' and multiple workers may duplicate your data.'
+                            ' Please consider using the`keras.utils.Sequence'
+                            ' class.'))
+        if steps_per_epoch is None:
+            if is_sequence:
+                steps_per_epoch = len(generator)
+            else:
+                raise ValueError('`steps_per_epoch=None` is only valid for a'
+                                 ' generator based on the `keras.utils.Sequence`'
+                                 ' class. Please specify `steps_per_epoch` or use'
+                                 ' the `keras.utils.Sequence` class.')
+
         # python 2 has 'next', 3 has '__next__'
         # avoid any explicit version checks
         val_gen = (hasattr(validation_data, 'next') or
                    hasattr(validation_data, '__next__') or
                    isinstance(validation_data, Sequence))
-        if val_gen and not validation_steps:
-            raise ValueError('When using a generator for validation data, '
-                             'you must specify a value for '
-                             '`validation_steps`.')
+        if (val_gen and not isinstance(validation_data, Sequence) and
+                not validation_steps):
+            raise ValueError('`validation_steps=None` is only valid for a'
+                             ' generator based on the `keras.utils.Sequence`'
+                             ' class. Please specify `validation_steps` or use'
+                             ' the `keras.utils.Sequence` class.')
 
         # Prepare display labels.
         out_labels = self._get_deduped_metrics_names()
@@ -2059,15 +2081,6 @@ class Model(Container):
                 val_data += [0.]
             for cbk in callbacks:
                 cbk.validation_data = val_data
-        is_sequence = isinstance(generator, Sequence)
-        if not is_sequence and use_multiprocessing and workers > 1:
-            warnings.warn(
-                UserWarning('Using a generator with `use_multiprocessing=True`'
-                            ' and multiple workers may duplicate your data.'
-                            ' Please consider using the`keras.utils.Sequence'
-                            ' class.'))
-        if is_sequence:
-            steps_per_epoch = len(generator)
         enqueuer = None
 
         try:
@@ -2173,7 +2186,7 @@ class Model(Container):
         return self.history
 
     @interfaces.legacy_generator_methods_support
-    def evaluate_generator(self, generator, steps,
+    def evaluate_generator(self, generator, steps=None,
                            max_queue_size=10,
                            workers=1,
                            use_multiprocessing=False):
@@ -2190,7 +2203,8 @@ class Model(Container):
                     when using multiprocessing.
             steps: Total number of steps (batches of samples)
                 to yield from `generator` before stopping.
-                Not used if using Sequence.
+                Optional for `Sequence`: if unspecified, will use
+                the `len(generator)` as a number of steps.
             max_queue_size: maximum size for the generator queue
             workers: maximum number of processes to spin up
                 when using process based threading
@@ -2225,8 +2239,14 @@ class Model(Container):
                             ' and multiple workers may duplicate your data.'
                             ' Please consider using the`keras.utils.Sequence'
                             ' class.'))
-        if is_sequence:
-            steps = len(generator)
+        if steps is None:
+            if is_sequence:
+                steps = len(generator)
+            else:
+                raise ValueError('`steps=None` is only valid for a generator'
+                                 ' based on the `keras.utils.Sequence` class.'
+                                 ' Please specify `steps` or use the'
+                                 ' `keras.utils.Sequence` class.')
         enqueuer = None
 
         try:
@@ -2288,7 +2308,7 @@ class Model(Container):
             return averages
 
     @interfaces.legacy_generator_methods_support
-    def predict_generator(self, generator, steps,
+    def predict_generator(self, generator, steps=None,
                           max_queue_size=10,
                           workers=1,
                           use_multiprocessing=False,
@@ -2305,7 +2325,8 @@ class Model(Container):
                     when using multiprocessing.
             steps: Total number of steps (batches of samples)
                 to yield from `generator` before stopping.
-                Not used if using Sequence.
+                Optional for `Sequence`: if unspecified, will use
+                the `len(generator)` as a number of steps.
             max_queue_size: Maximum size for the generator queue.
             workers: Maximum number of processes to spin up
                 when using process based threading
@@ -2337,8 +2358,14 @@ class Model(Container):
                             ' and multiple workers may duplicate your data.'
                             ' Please consider using the`keras.utils.Sequence'
                             ' class.'))
-        if is_sequence:
-            steps = len(generator)
+        if steps is None:
+            if is_sequence:
+                steps = len(generator)
+            else:
+                raise ValueError('`steps=None` is only valid for a generator'
+                                 ' based on the `keras.utils.Sequence` class.'
+                                 ' Please specify `steps` or use the'
+                                 ' `keras.utils.Sequence` class.')
         enqueuer = None
 
         try:
diff --git a/keras/models.py b/keras/models.py
index a53b1dd8..f4487f06 100644
--- a/keras/models.py
+++ b/keras/models.py
@@ -1116,7 +1116,7 @@ class Sequential(Model):
 
     @interfaces.legacy_generator_methods_support
     def fit_generator(self, generator,
-                      steps_per_epoch,
+                      steps_per_epoch=None,
                       epochs=1,
                       verbose=1,
                       callbacks=None,
@@ -1148,6 +1148,8 @@ class Sequential(Model):
                 finished and starting the next epoch. It should typically
                 be equal to the number of samples of your dataset
                 divided by the batch size.
+                Optional for `Sequence`: if unspecified, will use
+                the `len(generator)` as a number of steps.
             epochs: Integer, total number of iterations on the data.
                 Note that in conjunction with initial_epoch, the parameter
                 epochs is to be understood as "final epoch". The model is
@@ -1165,6 +1167,8 @@ class Sequential(Model):
                 at the end of every epoch. It should typically
                 be equal to the number of samples of your
                 validation dataset divided by the batch size.
+                Optional for `Sequence`: if unspecified, will use
+                the `len(validation_data)` as a number of steps.
             class_weight: Dictionary mapping class indices to a weight
                 for the class.
             max_queue_size: Maximum size for the generator queue
@@ -1223,7 +1227,7 @@ class Sequential(Model):
                                         initial_epoch=initial_epoch)
 
     @interfaces.legacy_generator_methods_support
-    def evaluate_generator(self, generator, steps,
+    def evaluate_generator(self, generator, steps=None,
                            max_queue_size=10, workers=1,
                            use_multiprocessing=False):
         """Evaluates the model on a data generator.
@@ -1236,6 +1240,8 @@ class Sequential(Model):
                 or (inputs, targets, sample_weights)
             steps: Total number of steps (batches of samples)
                 to yield from `generator` before stopping.
+                Optional for `Sequence`: if unspecified, will use
+                the `len(generator)` as a number of steps.
             max_queue_size: maximum size for the generator queue
             workers: maximum number of processes to spin up
             use_multiprocessing: if True, use process based threading.
@@ -1263,7 +1269,7 @@ class Sequential(Model):
                                              use_multiprocessing=use_multiprocessing)
 
     @interfaces.legacy_generator_methods_support
-    def predict_generator(self, generator, steps,
+    def predict_generator(self, generator, steps=None,
                           max_queue_size=10, workers=1,
                           use_multiprocessing=False, verbose=0):
         """Generates predictions for the input samples from a data generator.
@@ -1275,6 +1281,8 @@ class Sequential(Model):
             generator: generator yielding batches of input samples.
             steps: Total number of steps (batches of samples)
                 to yield from `generator` before stopping.
+                Optional for `Sequence`: if unspecified, will use
+                the `len(generator)` as a number of steps.
             max_queue_size: maximum size for the generator queue
             workers: maximum number of processes to spin up
             use_multiprocessing: if True, use process based threading.
